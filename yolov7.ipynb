{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(image_path):\n",
    "    image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32') / 255\n",
    "    return image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_images(image_path):\n",
    "    count = 0\n",
    "    for dir1 in os.listdir(image_path):\n",
    "        count += len(os.listdir(os.path.join(image_path, dir1)))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: 720, Width: 1280\n",
      "Training data size: 23501\n"
     ]
    }
   ],
   "source": [
    "image_height = get_size('train_images/video_0/0.jpg')[0]    # 720\n",
    "image_width = get_size('train_images/video_0/0.jpg')[1]     # 1280\n",
    "print(f\"Height: {image_height}, Width: {image_width}\")\n",
    "print(f\"Training data size: {num_images('train_images')}\")  # 23501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_folder):\n",
    "    image_data = []\n",
    "    class_names = []\n",
    "\n",
    "    for dir1 in os.listdir(image_folder):\n",
    "        for dir2 in os.listdir(os.path.join(image_folder, dir1)):\n",
    "            image_path = os.path.join(image_folder, dir1, dir2)\n",
    "            image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (image_height, image_width), interpolation = cv2.INTER_AREA)\n",
    "            image = np.array(image)\n",
    "            image = image.astype('float32') / 255\n",
    "            image_data.append(image)\n",
    "            class_names.append(dir1)\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(image_folder):\n",
    "    image_paths = []\n",
    "    while (len(image_paths) < 10):\n",
    "        for dir1 in os.listdir(image_folder):\n",
    "            for dir2 in os.listdir(os.path.join(image_folder, dir1)):\n",
    "                image_path = os.path.join(image_folder, dir1, dir2)\n",
    "                if (random.randint(0,10000) > 9999 and len(image_paths) < 10):\n",
    "                    image_paths.append(image_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_images(image_paths):\n",
    "    os.makedirs('test_images')\n",
    "    for i in range(0, len(image_paths)):\n",
    "        shutil.copy(image_paths[i], 'test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joeljose/Desktop/Coding Projects/python/comp9517/project/Crown-of-Throrns\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_images/video_2/9860.jpg', 'train_images/video_1/5743.jpg', 'train_images/video_1/4032.jpg', 'train_images/video_2/5869.jpg', 'train_images/video_0/9950.jpg', 'train_images/video_0/11619.jpg', 'train_images/video_2/9520.jpg', 'train_images/video_2/562.jpg', 'train_images/video_2/10677.jpg', 'train_images/video_0/11708.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_images = get_random_images('train_images')\n",
    "store_images(test_images)\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjustjo3l\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/joeljose/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in!\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "    api_key = \"f72dca236cb3497e771bf6c5ea119c25fcfb1b10\"\n",
    "    wandb.login(key=api_key)\n",
    "    anonymous = None\n",
    "    print('Logged in!')\n",
    "except:\n",
    "    wandb.login(anonymous='must')\n",
    "    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/joeljose/Desktop/Coding Projects/python/comp9517/project/Crown-of-Throrns/wandb/run-20221115_215830-3bidihjz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/justjo3l/Crown-of-Throrns/runs/3bidihjz\" target=\"_blank\">astral-yogurt-2</a></strong> to <a href=\"https://wandb.ai/justjo3l/Crown-of-Throrns\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_1w24g32k_model:v0, 315.54MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./artifacts/run_1w24g32k_model:v0\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('justjo3l/YOLOR/run_1w24g32k_model:v0', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "print(artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md            test.csv             \u001b[34mwandb\u001b[m\u001b[m\n",
      "\u001b[34martifacts\u001b[m\u001b[m            \u001b[34mtest_images\u001b[m\u001b[m          yolov7.ipynb\n",
      "detect.py            train.csv\n",
      "hog_svm_method.ipynb \u001b[34mtrain_images\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: yolov7: No such file or directory\n",
      "Cloning into 'yolov7'...\n",
      "remote: Enumerating objects: 998, done.\u001b[K\n",
      "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
      "Receiving objects: 100% (998/998), 69.77 MiB | 16.39 MiB/s, done.\n",
      "Resolving deltas: 100% (467/467), done.\n",
      "/Users/joeljose/Desktop/Coding Projects/python/comp9517/project/Crown-of-Throrns/yolov7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!rm -r yolov7\n",
    "!git clone https://github.com/WongKinYiu/yolov7.git # clone\n",
    "%cd yolov7\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'yolov7'\n",
      "/Users/joeljose/Desktop/Coding Projects/python/comp9517/project/Crown-of-Throrns/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the detect.py in yolov7 with the detect.py in the Crown-Of-Throrns repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['../artifacts/run_1w24g32k_model/best.pt'], source='../test_images', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "YOLOR 🚀 2022-11-15 torch 1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "IAuxDetect.fuse\n",
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/Users/joeljose/opt/anaconda3/envs/cotsenv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 819 layers, 164816216 parameters, 0 gradients, 225.4 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "Done. (4180.9ms) Inference, (6.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/10677.jpg\n",
      "Done. (3219.8ms) Inference, (0.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/11619.jpg\n",
      "Done. (1347.3ms) Inference, (0.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/11708.jpg\n",
      "Done. (1396.4ms) Inference, (0.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/4032.jpg\n",
      "Done. (1377.4ms) Inference, (0.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/562.jpg\n",
      "1 cots, Done. (1383.3ms) Inference, (5.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/5743.jpg\n",
      "2 cotss, Done. (1405.8ms) Inference, (0.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/5869.jpg\n",
      "Done. (1407.4ms) Inference, (0.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/9520.jpg\n",
      "Done. (1380.5ms) Inference, (0.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/9860.jpg\n",
      "Done. (1398.5ms) Inference, (0.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp2/9950.jpg\n",
      "Done. (18.875s)\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights ../artifacts/run_1w24g32k_model/best.pt --conf 0.1 --source ../test_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cotsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abbac26dc339ae0588c7ffd52f5050e511888da33c6bde075b35c45e09f0f307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
